---
title: AI Literature
description: ai resources
slug: ai-literature
date: 2024-03-13 00:00:00+0000
categories:
    - AI
    - LLMs      # You can add weight to some posts to override the default sorting (date descending)
---

## Resources
- [The Little Book of Deep Learning - François Fleuret](https://fleuret.org/francois/lbdl.html)
- [François Fleuret's deep learning course](https://fleuret.org/dlc/)
- [Jeremy Howard's courses](https://course.fast.ai/)
- [Karpathy's LLM Tokenizer Video](https://www.youtube.com/watch?v=zduSFxRajkE)
- [@arpitingle's ML Resources Stash](https://arc.net/e/D242E263-31FD-4CF9-A2D5-B67519C049AF)
- [Deep Learning (MIT Press Book)](https://www.deeplearningbook.org/)
  + this book covers everything up to just before transformers
- [LocalModelsPapers rentry link](https://rentry.org/LocalModelsPapers)

## Reading List 
- [LLM Reading List](https://gist.github.com/veekaybee/be375ab33085102f9027853128dc5f0e)
- [Unlimiformer - kNN inside transformers](https://arxiv.org/abs/2305.01625/)
- [How far can you train a model on a single consume GPU](https://arxiv.org/pdf/2212.14034.pdf)
- [Karpathy's course on building NNs from scratch](https://karpathy.ai/zero-to-hero.html)
- [Reinforcement Learning (intro)](http://incompleteideas.net/book/the-book-2nd.html)


> links below from [yacine.ca](https://yacine.ca/)

- https://arxiv.org/abs/2209.04836
  - Git re-basin
- https://arxiv.org/pdf/2212.04089.pdf
  - editing models with task arithmetic
- [Ologs (ontology log) ](https://math.mit.edu/~dspivak/informatics/olog.pdf)
- [GLaM](https://arxiv.org/pdf/2112.06905.pdf)
- [DEMix Layers](https://arxiv.org/pdf/2108.05036.pdf)
- [Branch-Train-Merge](https://arxiv.org/pdf/2208.03306.pdf)
- [Cluster-BTM](https://arxiv.org/abs/2303.14177)
- [SMEAR](https://arxiv.org/pdf/2306.03745.pdf)
- [TIES-Merging](https://arxiv.org/abs/2306.01708)
- [AdapterFusion](https://arxiv.org/pdf/2005.00247.pdf)
- [KNN Zero-Shot Inference](https://suchin.io/assets/knnprompt.pdf)
- [Cross-Task Skills with Task-Level Mixture-of-Experts](https://arxiv.org/abs/2205.12701)
- [Mixture-of-Supernets](https://arxiv.org/pdf/2306.04845.pdf)
- [Sparse Upcycling](https://arxiv.org/abs/2212.05055)
- [AdaMix](https://www.microsoft.com/en-us/research/uploads/prod/2022/05/Mixture_of_Adaptations_EMNLP_2022-2.pdf) 
- [Prompting Large Language Models with Speech Recognition Abilities](https://arxiv.org/pdf/2307.11795.pdf)
- https://arxiv.org/pdf/2307.11795.pdf
  - speech recognition with palm-e like strategy

https://dreamtuner-diffusion.github.io/ - ipadapter but different  
https://arxiv.org/pdf/2312.13789.pdf - how i beat the big wigs
https://arxiv.org/abs/2312.09608 - faster stable diffusion by skipping unecessary bits  
https://github.com/damo-vilab/AnyDoor - instruct edit + https://old.reddit.com/r/StableDiffusion/comments/18kd0na/ code_for_anydoor_zeroshot_objectlevel_image/  
dont forget - diffusion slider demo https://github.com/Kevin-thu/DiffMorpher?tab=readme-ov-file  
https://arxiv.org/pdf/2312.01943.pdf - anime  
https://huggingface.co/spaces/JingyeChen22/TextDiffuser-2   
https://github.com/open-mmlab/PIA - video generator  
https://github.com/cumulo-autumn/StreamDiffusion - turbo go fast  

